{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.SyntheticDataset import gaussianGridDataset, ringDataset, circleDataset\n",
    "from Online_Kernel_GAN import Online_Kernel_GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's make a 2d synthetic dataset\n",
    "## (1) Gaussian 2d grid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = {\n",
    "            'num_grid':5,\n",
    "            'n_data':100,\n",
    "            'sigma':0.05\n",
    "        }\n",
    "data_gaussiangrid = gaussianGridDataset(n=data_config['num_grid'], n_data=data_config['n_data'], sig=data_config['sigma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's create and train the GAN on this dataset\n",
    "\n",
    "A gamma value starts from 0.2 and increases with a ratio of 1.002 after every epoch. We can observe that the GAN with the online kernel classifier learns a gaussian 2d grid distribution. All images are saved in 'out_image/out_gaussian2d_online_kernel'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_gaussian2d = Online_Kernel_GAN(gamma=0.2, gamma_ratio=1.0015, lr_gamma=0.999, budget=4096, num_epochs=3000, batch_size=500, data=data_gaussiangrid)\n",
    "gan_gaussian2d.train_GAN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Ring 2d dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = {\n",
    "            'num_mode':8,\n",
    "            'n_data':300,\n",
    "            'sigma':0.05,\n",
    "            'radius':4\n",
    "        }\n",
    "data_ring = ringDataset(n=data_config['num_mode'], n_data=data_config['n_data'], sig=data_config['sigma'], r=data_config['radius'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images are saved in 'out_image/out_gaussian2d_online_kernel'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_ring2d = Online_Kernel_GAN(gamma=0.2, gamma_ratio=1.0015, lr_gamma=0.999, budget=4096, num_epochs=3000, batch_size=500, data=data_ring)\n",
    "gan_ring2d.train_GAN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Circle 2d dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = {\n",
    "            'n_data':30,\n",
    "            'sigma':0.05,\n",
    "            'radius':2\n",
    "        }\n",
    "data_circle = circleDataset(n_data=data_config['n_data'], sig=data_config['sigma'], r=data_config['radius'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images are saved in 'out_image/out_gaussian2d_online_kernel'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_circle2d = Online_Kernel_GAN(gamma=0.2, gamma_ratio=1.0015, lr_gamma=0.999, budget=4096, num_epochs=3000, batch_size=500, data=data_circle)\n",
    "gan_circle2d.train_GAN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's play with the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "img_size = 64\n",
    "\n",
    "def mnist_data():\n",
    "    compose = transforms.Compose(\n",
    "        [transforms.Resize(img_size),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize((.5,), (.5,))\n",
    "        ])\n",
    "    out_dir = 'data'\n",
    "    return datasets.MNIST(root=out_dir, train=True, transform=compose, download=True)\n",
    "\n",
    "data_mnist = mnist_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on MNIST\n",
    "\n",
    "In this experiment, we use a polynomial kernel and fix the gamma value as 1/784. All images are saved in 'out_image/out_mnist_online_kernel'. There is an error when we try to change the model into \"DCGAN\". If a budget constraint of the online kernel classifier is large, the online kernel classifier shows high accuracy on a binary classification task of MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_mnist = Online_Kernel_GAN(kernel='gaussian', lr=0.0002, gamma=0.01, gamma_ratio=1.0, budget=700, g_steps=10, num_epochs=200, batch_size=200, img_size=img_size, data=data_mnist, data_type='mnist', model_type='DCGAN')\n",
    "gan_mnist.train_GAN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's play with the SVHN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "# Tensor transform\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "    ])\n",
    "\n",
    "# SVHN training datasets\n",
    "data_svhn = datasets.SVHN(root='data/', split='train', download=True, transform=transform)\n",
    "print(len(data_svhn))\n",
    "\n",
    "img_size = 32\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on SVHN\n",
    "\n",
    "In this experiment, we use a polynomial kernel and fix the gamma value as 0.01. All images are saved in 'out_image/out_svhn_online_kernel'. I implemented the encoder in the online kernel classifier in order to calculate kernel with image data. I observed that GAN works better when a size of budget is smaller than one for a binary classification task of MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_svhn = Online_Kernel_GAN(kernel='poly', lr=0.0002, gamma=0.01, gamma_ratio=1.0, budget=2000, g_steps=1, num_epochs=200, batch_size=batch_size, img_size=img_size, data=data_svhn, data_type='svhn', model_type='DCGAN')\n",
    "gan_svhn.train_GAN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's play with the CelebA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img_size = 64\n",
    "batch_size = 128\n",
    "dataroot = \"data/celeba\"\n",
    "\n",
    "data_celeba = datasets.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(img_size),\n",
    "                               transforms.CenterCrop(img_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((.5, .5, .5), (.5, .5, .5)),\n",
    "                           ]))\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(data_celeba, batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Plot some training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on CelebA\n",
    "In this experiment, we use a mixed gaussian kernel. You can try another kernels in 'online_kernel_classifier.py'. We found out that mixed gaussian kernel works best. All images are saved in 'out_image/out_celeba_online_kernel'. I implemented the encoder in the online kernel classifier in order to calculate kernel with image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_celeba = Online_Kernel_GAN(kernel='mixed_gaussian', lr=0.0002, gamma=torch.tensor([1/(2*2**2), 1/(2*5**2), 1/(2*10**2), 1/(2*20**2), 1/(2*40**2), 1/(2*80**2)]), gamma_ratio=1.0, alpha=0.5, budget=1000, g_steps=3, num_epochs=7, batch_size=batch_size, img_size=img_size, data=data_celeba, data_type='celeba', model_type='DCGAN')\n",
    "gan_celeba.train_GAN()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_pytorch",
   "language": "python",
   "name": "conda-env-py37_pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
