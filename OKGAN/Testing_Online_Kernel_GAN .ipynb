{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.SyntheticDataset import gaussianGridDataset, ringDataset, nonuniform_ringDataset, circleDataset, swissrollDataset, twospiralsDataset\n",
    "from data.gmmDataset import gmmDataset\n",
    "from data.PoissonDigitDataset import PoissonDigitDataset\n",
    "from Online_Kernel_GAN import Online_Kernel_GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's make a 2d synthetic dataset\n",
    "## (1) Gaussian 2d grid dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to do the experiment on 7 * 7 2d grid dataset, please change 'num_grid' into 7 and 'n_data' into 200. Also, you need to change the initial gamma value into 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = {\n",
    "            'num_grid':5,\n",
    "            'n_data':400,\n",
    "            'sigma':0.05\n",
    "        }\n",
    "data_gaussiangrid = gaussianGridDataset(n=data_config['num_grid'], n_data=data_config['n_data'], sig=data_config['sigma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's create and train the GAN on this dataset\n",
    "\n",
    "A gamma value starts from 0.2 and increases with a ratio of 1.002 after every epoch. We can observe that the GAN with the online kernel classifier learns a gaussian 2d grid distribution. All images are saved in 'out_image/out_gaussian2d_online_kernel'. If you want to do the cycling behavior experiment, please comment out first two lines in the below cell and run the following four lines.(remove comments of four lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_gaussian2d = Online_Kernel_GAN(gamma=1, gamma_ratio=1, lr_gamma=1, lr_schedule=[(1500, 5e-5), (3000, 5e-6)], budget=4096, lossfn='hinge', num_epochs=4000, batch_size=500, data=data_gaussiangrid)\n",
    "#gan_gaussian2d = Online_Kernel_GAN(kernel='IKL', gamma=1, gamma_ratio=1, lr_gamma=1, lr_schedule=[(1500, 5e-5), (3000, 5e-6)], lr_IKL=1e-4, lr_IKL_schedule=None, budget=4096, lossfn='hinge', g_steps=5, IKL_steps=5, lmbda_IKL=0.0, var_IKL=0.0, num_epochs=4000, batch_size=500, data=data_gaussiangrid)\n",
    "gan_gaussian2d.train_GAN()\n",
    "# 1hidden32\n",
    "#%pylab inline\n",
    "#fig, ax = plt.subplots(figsize=(8, 8))\n",
    "#gan_gaussian2d = Online_Kernel_GAN(kernel='IKL', lr_schedule=[(1500, 5e-5), (3000, 5e-6)], lr_IKL=1e-4, budget=4096, lossfn='hinge', g_steps=5, IKL_steps=5, num_epochs=40, batch_size=50, data=data_gaussiangrid)\n",
    "#gan_gaussian2d = Online_Kernel_GAN(gamma=0.2, gamma_ratio=1.002, budget=4096, num_epochs=20, batch_size=50, data=data_gaussiangrid)\n",
    "#gan_gaussian2d.train_GAN(plotter=plt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Ring 2d dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = {\n",
    "            'num_mode':8,\n",
    "            'n_data':1000,\n",
    "            'sigma':0.01,\n",
    "            'radius':1\n",
    "        }\n",
    "data_ring = ringDataset(n=data_config['num_mode'], n_data=data_config['n_data'], sig=data_config['sigma'], r=data_config['radius'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial gamma value is 3.2 because radius is 1 in this case. All images are saved in 'out_image/out_gaussian2d_online_kernel'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_ring2d = Online_Kernel_GAN(gamma=16, gamma_ratio=1, lr_gamma=1, lr_schedule=[(1500, 5e-5), (3000, 5e-6)], budget=4096, lossfn='hinge', num_epochs=5000, batch_size=500, data=data_ring)\n",
    "gan_ring2d.train_GAN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonuniform ring 2d dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = {\n",
    "            'num_mode':8,\n",
    "            'n_data':10000,\n",
    "            'sigma':0.01,\n",
    "            'radius':1\n",
    "        }\n",
    "data_ring = nonuniform_ringDataset(n=data_config['num_mode'], n_data=data_config['n_data'], sig=data_config['sigma'], r=data_config['radius'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_nonuniform_ring2d = Online_Kernel_GAN(gamma=16, gamma_ratio=1, lr_gamma=1, lr_schedule=[(1500, 5e-5), (3000, 5e-6)], budget=4096, lossfn='hinge', num_epochs=4000, batch_size=500, data=data_ring)\n",
    "gan_nonuniform_ring2d.train_GAN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Circle 2d dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = {\n",
    "            'n_data':100,\n",
    "            'sigma':0.05,\n",
    "            'radius':2\n",
    "        }\n",
    "data_circle = circleDataset(n_data=data_config['n_data'], sig=data_config['sigma'], r=data_config['radius'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images are saved in 'out_image/out_gaussian2d_online_kernel'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_circle2d = Online_Kernel_GAN(gamma=0.2, gamma_ratio=1.0015, lr_gamma=0.999, budget=4096, num_epochs=3000, batch_size=500, data=data_circle)\n",
    "gan_circle2d.train_GAN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) SwissRoll 2d dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = {\n",
    "            'n_data':10000,\n",
    "            'noise':0.2\n",
    "}\n",
    "data_swissroll = swissrollDataset(n_data=data_config['n_data'], noise=data_config['noise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_swissroll2d = Online_Kernel_GAN(gamma=1, gamma_ratio=1, lr_gamma=1, lr_schedule=[(1500, 5e-5), (3000, 5e-6)], budget=4096, lossfn='hinge', num_epochs=4000, batch_size=500, data=data_swissroll)\n",
    "gan_swissroll2d.train_GAN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) 2 Spirals 2d dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = {\n",
    "            'n_data':10000,\n",
    "            'sig':0.02\n",
    "}\n",
    "data_2spirals = twospiralsDataset(n_data=data_config['n_data'], sig=data_config['sig'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_2spirals2d = Online_Kernel_GAN(gamma=10, gamma_ratio=1, lr_gamma=1, lr_schedule=[(1000, 5e-5), (2000, 5e-6), (3000, 5e-7)], budget=4096, lossfn='logistic', num_epochs=4000, batch_size=500, data=data_2spirals)\n",
    "gan_2spirals2d.train_GAN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) GMM 2d dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = {\n",
    "            'n_data':10000,\n",
    "            'custom':True,\n",
    "            'tightness':4,\n",
    "            'n_clusters':5\n",
    "}\n",
    "data_gmm = gmmDataset(n_data=data_config['n_data'], custom=data_config['custom'], tightness=data_config['tightness'], n_clusters=data_config['n_clusters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_gmm2d = Online_Kernel_GAN(gamma=10, gamma_ratio=1, lr=5e-4, lr_gamma=1, lr_schedule=[(1500, 5e-5), (3000, 5e-6)], budget=4096, lossfn='hinge', num_epochs=4000, batch_size=500, data=data_gmm)\n",
    "gan_gmm2d.train_GAN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's play with the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "img_size = 28\n",
    "code_dim = 16 #dimension of the code space\n",
    "\n",
    "def mnist_data():\n",
    "    compose = transforms.Compose(\n",
    "        [transforms.Resize(img_size),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize((.5,), (.5,))\n",
    "        ])\n",
    "    out_dir = 'data'\n",
    "    return datasets.MNIST(root=out_dir, train=True, transform=compose, download=True)\n",
    "\n",
    "data_mnist = mnist_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on MNIST\n",
    "\n",
    "In this experiment, we use Gaussian kernel and fix the gamma value as 0.01. All images are saved in 'out_image/out_mnist_online_kernel'. We can also check the performance of OKGAN which does not contain the encoder architecture. If you want to run OKGAN without the encoder, please comment out the first line of the below cell, delete # in the second line, and change img_size from 64 into 28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gan_mnist = Online_Kernel_GAN(kernel='gaussian', lr=0.0002, gamma=0.01, gamma_ratio=1.0, budget=700, g_steps=10, num_epochs=200, batch_size=200, img_size=img_size, data=data_mnist, data_type='mnist', model_type='DCGAN')\n",
    "gan_mnist = Online_Kernel_GAN(kernel='IKL', lr=0.0002, lr_IKL=1e-4, gamma=0.01, gamma_ratio=1.0, budget=30000, lossfn='hinge', g_steps=3, IKL_steps=10, num_epochs=200, batch_size=200, img_size=img_size, code_dim=code_dim, data=data_mnist, data_type='mnist', model_type='GAN with AE')\n",
    "gan_mnist.train_GAN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's play with Poisson Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "img_size = 28\n",
    "code_dim = 16 #dimension of the code space\n",
    "batch_size = 128\n",
    "\n",
    "compose = transforms.Compose(\n",
    "        [transforms.Resize(img_size),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize((.5,), (.5,))\n",
    "        ])\n",
    "\n",
    "dl = DataLoader(datasets.MNIST('./data/mnist', train=True, transform=compose, download=True), batch_size=60000, shuffle=False)\n",
    "for _, full_batch in enumerate(dl):\n",
    "    train_data = full_batch[0]\n",
    "    train_labels = full_batch[1]\n",
    "\n",
    "mnist_tensor = train_data.to(dtype=torch.float32)\n",
    "mnist_tensor = mnist_tensor.reshape(mnist_tensor.shape[0], -1) \n",
    "\n",
    "mnist_df = pd.DataFrame(mnist_tensor.cpu().numpy())\n",
    "mnist_df['label'] = train_labels.cpu().numpy()\n",
    "\n",
    "MNIST_DIGITS = [\n",
    "    mnist_df[\n",
    "        mnist_df['label'] == ind\n",
    "    ].drop('label',axis=1).values.reshape([-1,28,28]) \n",
    "    for ind in range(10)\n",
    "]\n",
    "\n",
    "def display_poisson_digits(mean=100,num_digits=3):\n",
    "    # Here we pick a random integer from the poisson distribution\n",
    "    digits = np.random.poisson(mean)\n",
    "    # This is the list of the digits in this number\n",
    "    digits_lst = list(map(int, list(str(digits))))\n",
    "    num_dig = len(digits_lst)\n",
    "    if num_digits < num_dig:\n",
    "        return None\n",
    "    digs = [0 for _ in range(num_digits - num_dig )] + digits_lst\n",
    "    out = []\n",
    "    # out is a list of mnist digits corres\n",
    "    for dig in digs:\n",
    "        digims = MNIST_DIGITS[dig]\n",
    "        randind = np.random.randint(low=0,high=digims.shape[0])\n",
    "        choice = digims[randind]\n",
    "        out.append(choice)\n",
    "    return np.hstack(out), digits\n",
    "\n",
    "rand_three_dig_num, digits = display_poisson_digits(num_digits=3)\n",
    "print(digits)\n",
    "plt.imshow(rand_three_dig_num)\n",
    "\n",
    "data_poisson_digit = PoissonDigitDataset(display_poisson_digits, n_data=100000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_poisson_digit = Online_Kernel_GAN(kernel='IKL', lr=0.0002, lr_IKL=1e-4, gamma=0.01, gamma_ratio=1.0, budget=30000, lossfn='hinge', g_steps=3, IKL_steps=10, num_epochs=200, batch_size=batch_size, img_size=img_size, code_dim=code_dim, data=data_poisson_digit, data_type='poisson_digit', model_type='GAN with AE')\n",
    "gan_poisson_digit.train_GAN()\n",
    "#gan_poisson_digit.calculate_reverse_KL(lenet_path='./lenet_checkpoint/saved_lenet', model_path='./checkpoint/checkpoint_poisson_digit_online_kernel/gen_200')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's play with the SVHN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "# Tensor transform\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "    ])\n",
    "\n",
    "# SVHN training datasets\n",
    "data_svhn = datasets.SVHN(root='data/', split='train', download=True, transform=transform)\n",
    "print(len(data_svhn))\n",
    "\n",
    "img_size = 32\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on SVHN\n",
    "\n",
    "In this experiment, we use a polynomial kernel and fix the gamma value as 0.01. All images are saved in 'out_image/out_svhn_online_kernel'. I implemented the encoder in the online kernel classifier in order to calculate kernel with image data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_svhn = Online_Kernel_GAN(kernel='poly', lr=0.0002, gamma=0.01, gamma_ratio=1.0, budget=2000, g_steps=1, num_epochs=200, batch_size=batch_size, img_size=img_size, data=data_svhn, data_type='svhn', model_type='DCGAN')\n",
    "gan_svhn.train_GAN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's play with the CelebA dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you run the below codes, please download the img_align_celeba.zip from the [Google Drive](https://drive.google.com/drive/folders/0B7EVK8r0v71pTUZsaXdaSnZBZzg). Once you download it, extract the zip file into \"data/celeba\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img_size = 64\n",
    "batch_size = 128\n",
    "dataroot = \"data/celeba\"\n",
    "\n",
    "data_celeba = datasets.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(img_size),\n",
    "                               transforms.CenterCrop(img_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((.5, .5, .5), (.5, .5, .5)),\n",
    "                           ]))\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(data_celeba, batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Plot some training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on CelebA\n",
    "In this experiment, we use a mixed gaussian kernel. You can try another kernels in 'online_kernel_classifier.py'. We found out that mixed gaussian kernel works best. All images are saved in 'out_image/out_celeba_online_kernel'. I implemented the encoder in the online kernel classifier in order to calculate kernel with image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_celeba = Online_Kernel_GAN(kernel='mixed_gaussian', lr=0.0002, gamma=torch.tensor([1/(2*2**2), 1/(2*5**2), 1/(2*10**2), 1/(2*20**2), 1/(2*40**2), 1/(2*80**2)]), gamma_ratio=1.0, alpha=0.5, budget=1000, g_steps=3, num_epochs=7, batch_size=batch_size, img_size=img_size, data=data_celeba, data_type='celeba', model_type='DCGAN')\n",
    "gan_celeba.train_GAN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's play with the CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img_size = 32\n",
    "#code_dim = 16\n",
    "batch_size = 128\n",
    "\n",
    "data_cifar10 = datasets.CIFAR10(root=\"./data\", download=True,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.RandomHorizontalFlip(),\n",
    "                               #transforms.Resize(img_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(data_cifar10, batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Plot some training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_cifar10 = Online_Kernel_GAN(kernel='mixed_gaussian', lr=0.0002, gamma=torch.tensor([1/(2*2**2), 1/(2*5**2), 1/(2*10**2), 1/(2*20**2), 1/(2*40**2), 1/(2*80**2)]), gamma_ratio=1.0, alpha=0.5, lossfn='hinge', budget=1000, g_steps=3, num_epochs=125, batch_size=batch_size, img_size=img_size, data=data_cifar10, data_type='cifar10', model_type='DCGAN')\n",
    "#gan_cifar10 = Online_Kernel_GAN(kernel='IKL', lr=0.0002, lr_IKL=1e-4, gamma=0.01, gamma_ratio=1.0, budget=1000, lossfn='hinge', g_steps=3, IKL_steps=10, num_epochs=25, batch_size=batch_size, img_size=img_size, code_dim=code_dim, data=data_cifar10, data_type='cifar10', model_type='DCGAN')\n",
    "gan_cifar10.train_GAN()\n",
    "#gan_cifar10.calculate_score(model_path='./checkpoint/checkpoint_cifar10/gen_032')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
